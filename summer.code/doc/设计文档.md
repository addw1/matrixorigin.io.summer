## Code Chat Bot

### 前言

本系统旨在设计一个学习平台，通过问答的形式帮助用户快速掌握特定GitHub仓库的代码。用户可以上传自己希望学习的仓库URL，系统会自动分析并生成总结。随后，用户可以基于仓库内容提出相关问题，系统将智能回答，帮助用户高效学习。



### 面临的业务问题的技术难点

**端到云的信息传输**：用户在PC端提出的问题需要上传至云端进行订阅处理。

**云到端的实时推送**：系统利用LLM生成回答后，需要将结果实时推送到用户端。



### 技术难点

**消息传递**：确保消息在端到云和云到端传输过程中的可靠性和实时性，避免数据丢失或延迟。

**回答质量**：提升LLM的准确性和上下文理解能力，确保其能够正确理解并回答用户问题



### 端到云的实现细节

**传统方案1：直接通过Web-Server写DB**

<img src=".\image-20241023230636190.png" alt="image-20241023230636190" style="zoom:33%;" />

**:cactus: 潜在不足**：所有业务都耦合在了Web-Server中，导致系统**灵活性和可维护性**下降。一旦需要扩展或修改某一功能，可能会影响整个系统的稳定性和性能，**耦合性高**使得单独维护、测试或扩展某一模块变得困难，降低了开发效率。



**传统方案2: 拆解出Web-Server层和业务服务层，Web-Server层通过RPC对业务服务进行调用**

<img src=".\image-20241023231450091.png" alt="image-20241023231450091" style="zoom:33%;" />

**:ice_cream: 潜在不足**：web-server与业务线的app-server存在耦合，当前需要通过**switch case**来区分业务线类型并分发消息，导致每当新增业务线时，必须添加新的RPC调用。这样增加了**系统复杂度**，降低了**灵活性**，且**扩展成本**较高。



**优化方案**

本系统通过引入mq，达到解耦合异步化的目的。消息平台只需要持久化消息并发送到mq即可。而未来如果新增加了其他server，只需要订阅相关主题进行消费，实现了消息平台与业务的解耦。

<img src=".\image-20241023231908482.png" alt="image-20241023231908482" style="zoom:33%;" />

### 云到端的实现细节

**读扩散vs写扩散**

读扩散：每个信息发送方（本系统既**LLM Server**）将产生的消息写入自己的写信箱。其他消息接收方通过读取写信箱获取最新消息。
优点在于写压力小，一条消息只用写入一次即可。但是读压力的较大。 

写扩散：消息发送方需要将消息发送到每个用户的写信箱。消息接收方读取自己的收信箱。优点在于该架构实现简单，但是写压力大。特别是在多人群聊的场景下，会达到1:N的写入比（N为群人数）。



**读扩散实现细节**

本系统最终采用读扩散模式进行实现。需要考虑“读扩散”让每个用户的消息从对应的“群会话消息队列同步“数据，而不是从”用户队列同步“数据。

其中**同步队列**围绕队列offset偏移量进行，通过队列的自增**syncId**保证有序，每个客户端维护相应的队列的同步位点，采取“客户端存储位点的去中心化“方案，实现”下行消息的推拉“结合。

通过队列位点syncId进行比对，如果服务端消息队列syncId-客户端队列syncId=1，表示云端消息无空洞，否则携带客户端的队列和对应的syncId到云端重新同步区间数据，实现最终一致性。

具体步骤如下：

:one: LLM Server 仓库消息后，把消息写入写信箱，并得到该条消息的**ID**。
:two:将消息ID传输到`msg_sever`
:three: msg_server将信息更新的消息推送到客户端
:four: 客户端基于当前存储的offset，读取写信箱的最新消息



